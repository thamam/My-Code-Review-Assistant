import { GoogleGenAI } from "@google/genai";
import { PRData, Diagram } from '../types';

export class DiagramAgent {
  private ai: GoogleGenAI;

  constructor() {
    this.ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
  }

  async proposeDiagrams(prData: PRData): Promise<Diagram[]> {
    const fileContext = prData.files
      .filter(f => f.status !== 'deleted' && (f.path.endsWith('.ts') || f.path.endsWith('.tsx') || f.path.endsWith('.py') || f.path.endsWith('.js')))
      .map(f => `File: ${f.path}\nContent:\n${(f.newContent || '').slice(0, 3000)}`)
      .join('\n\n');

    const prompt = `
      You are Theia, the goddess of sight and a specialized Software Architecture Agent. Your goal is to make the invisible structures of code visible. 
      Analyze these Pull Request changes and generate Mermaid.js Sequence Diagrams.

      PR Title: ${prData.title}
      PR Description: ${prData.description}

      CODE CONTEXT:
      ${fileContext}

      INSTRUCTIONS:
      1. Identify the 1-3 most critical logic flows.
      2. Return ONLY a JSON array. 
      
      Rules for Mermaid:
      - Use 'sequenceDiagram'.
      - CRITICAL: Every message (arrow) or Note MUST include the source code location at the end of the text in parentheses.
      - FORMAT: "Message Description (filename:line)". 
      - EXAMPLE: "processData (api.ts:42)" or "Note right of Auth: Validate Token (auth.ts:12)".
      - Use filenames that exist in the provided CODE CONTEXT.
      - If you use 'activate ParticipantName', you MUST follow it with 'deactivate ParticipantName' later in the flow.

      JSON Schema:
      [
        {
          "title": "Short title",
          "description": "Explanation",
          "mermaidCode": "sequenceDiagram\n..."
        }
      ]
    `;

    try {
      const response = await this.ai.models.generateContent({
        model: 'gemini-3-flash-preview',
        contents: prompt,
        config: {
          responseMimeType: "application/json"
        }
      });

      const text = response.text;
      if (!text) throw new Error("No response from AI");

      const rawDiagrams = JSON.parse(text);
      
      return rawDiagrams.map((d: any, idx: number) => ({
        id: `auto-diagram-${Date.now()}-${idx}`,
        title: d.title,
        description: d.description,
        mermaidCode: d.mermaidCode,
        timestamp: Date.now(),
        isAutoGenerated: true
      }));
    } catch (e) {
      console.error("Diagram Generation Failed", e);
      throw e;
    }
  }

  async generateCustomDiagram(prData: PRData, userPrompt: string): Promise<Diagram> {
    const fileContext = prData.files
        .slice(0, 5)
        .map(f => `File: ${f.path}\nContent:\n${(f.newContent || '').slice(0, 2000)}`)
        .join('\n\n');

    const prompt = `
      Generate a Mermaid.js Sequence Diagram for: "${userPrompt}"
      
      You are Theia, bring light to this architecture.
      
      PR Context:
      ${fileContext}

      Return ONLY a JSON object.
      IMPORTANT: Every message/note MUST include the source location: "Description (filename:line)".
      
      {
         "title": "Title",
         "description": "Brief description",
         "mermaidCode": "sequenceDiagram\n..."
      }
    `;

    const response = await this.ai.models.generateContent({
        model: 'gemini-3-flash-preview',
        contents: prompt,
        config: { responseMimeType: "application/json" }
    });
    
    const data = JSON.parse(response.text!);
    
    return {
        id: `custom-diagram-${Date.now()}`,
        title: data.title,
        description: data.description,
        mermaidCode: data.mermaidCode,
        timestamp: Date.now(),
        isAutoGenerated: false
    };
  }
}